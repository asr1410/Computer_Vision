{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 10:27:51.593 Python[1439:23647] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_keypoints_and_descriptors(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def find_good_matches(descriptors1, descriptors2):\n",
    "    flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict())\n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "    return good_matches\n",
    "\n",
    "def find_corresponding_points(image1, image2):\n",
    "    keypoints1, descriptors1 = find_keypoints_and_descriptors(image1)\n",
    "    keypoints2, descriptors2 = find_keypoints_and_descriptors(image2)\n",
    "    \n",
    "    good_matches = find_good_matches(descriptors1, descriptors2)\n",
    "\n",
    "    points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    return points1, points2\n",
    "\n",
    "def compute_essential_matrix(points1, points2):\n",
    "    fundamental_matrix, _ = cv2.findFundamentalMat(points1, points2, cv2.FM_LMEDS)\n",
    "    return fundamental_matrix\n",
    "\n",
    "def rectify_images(image1, image2, points1, points2):\n",
    "    fundamental_matrix = compute_essential_matrix(points1, points2)\n",
    "    _, homography1, homography2 = cv2.stereoRectifyUncalibrated(points1, points2, fundamental_matrix, image1.shape[:2])\n",
    "\n",
    "    rectified_image1 = cv2.warpPerspective(image1, homography1, image1.shape[:2][::-1])\n",
    "    rectified_image2 = cv2.warpPerspective(image2, homography2, image2.shape[:2][::-1])\n",
    "\n",
    "    return rectified_image1, rectified_image2\n",
    "\n",
    "def main(image_path1, image_path2):\n",
    "    image1 = cv2.imread(image_path1)\n",
    "    image2 = cv2.imread(image_path2)\n",
    "\n",
    "    points1, points2 = find_corresponding_points(image1, image2)\n",
    "    rectified_image1, rectified_image2 = rectify_images(image1, image2, points1, points2)\n",
    "\n",
    "    cv2.imshow('Original Image 1', image1)\n",
    "    cv2.imshow('Original Image 2', image2)\n",
    "    cv2.imshow('Rectified Image 1', rectified_image1)\n",
    "    cv2.imshow('Rectified Image 2', rectified_image2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path1 = './sample_left.png'\n",
    "    image_path2 = './sample_right.png'\n",
    "\n",
    "    main(image_path1, image_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_harris_corners(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = np.float32(gray_image)\n",
    "    corner_response = cv2.cornerHarris(gray_image, 2, 3, 0.04)\n",
    "    corner_response = cv2.dilate(corner_response, None)\n",
    "    image[corner_response > 0.01 * corner_response.max()] = [0, 0, 255]  # Mark corners in red\n",
    "\n",
    "    return image\n",
    "\n",
    "def main_harris_corner_detection(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    corners_image = detect_harris_corners(image)\n",
    "\n",
    "    cv2.imshow('Harris Corner Detection', corners_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path = './sample_left.png'\n",
    "    main_harris_corner_detection(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
